{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654ff0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output directory exp\\ch128_wavRegressor\\logs/checkpoint\n",
      "WaveNet_regressor Parameters: 3.988097M\n",
      "No valid checkpoint model found, start training from initialization.\n",
      "3  files loaded.  4375  training examples loaded\n",
      "3  files loaded.  522  training examples loaded\n",
      "iteration: 0 \\ training loss: 1.0077443929279553 \\ validation loss: 1.3010095059871674\n",
      "--- 19.34950828552246 seconds ---\n",
      "iteration: 50 \\ training loss: 0.29676662823733163 \\ validation loss: 1.772718071937561\n",
      "--- 18.89747405052185 seconds ---\n",
      "iteration: 100 \\ training loss: 0.10382329913623192 \\ validation loss: 1.823024645447731\n",
      "--- 20.52810025215149 seconds ---\n",
      "iteration: 150 \\ training loss: 0.058204682434306425 \\ validation loss: 1.7824696004390717\n",
      "--- 20.402424097061157 seconds ---\n",
      "iteration: 200 \\ training loss: 0.03702635778223767 \\ validation loss: 1.7559778094291687\n",
      "--- 20.408427238464355 seconds ---\n",
      "model at iteration 200 is saved\n",
      "iteration: 250 \\ training loss: 0.028943457805058536 \\ validation loss: 1.738354966044426\n",
      "--- 20.441338062286377 seconds ---\n",
      "iteration: 300 \\ training loss: 0.020840836935402715 \\ validation loss: 1.7540212720632553\n",
      "--- 20.454304218292236 seconds ---\n",
      "iteration: 350 \\ training loss: 0.016327696126502228 \\ validation loss: 1.7294210195541382\n",
      "--- 20.35157871246338 seconds ---\n",
      "iteration: 400 \\ training loss: 0.012083170867031989 \\ validation loss: 1.7194356173276901\n",
      "--- 20.461947441101074 seconds ---\n",
      "model at iteration 400 is saved\n",
      "iteration: 450 \\ training loss: 0.0105509753612911 \\ validation loss: 1.7262856513261795\n",
      "--- 20.329638957977295 seconds ---\n",
      "iteration: 500 \\ training loss: 0.00864261931137127 \\ validation loss: 1.6903686672449112\n",
      "--- 20.34260320663452 seconds ---\n",
      "iteration: 550 \\ training loss: 0.008666812805184984 \\ validation loss: 1.6736709773540497\n",
      "--- 20.33738088607788 seconds ---\n",
      "iteration: 600 \\ training loss: 0.006202438216218177 \\ validation loss: 1.687511146068573\n",
      "--- 20.349552631378174 seconds ---\n",
      "model at iteration 600 is saved\n",
      "iteration: 650 \\ training loss: 0.007078688482151312 \\ validation loss: 1.6924397945404053\n",
      "--- 20.405853748321533 seconds ---\n",
      "iteration: 700 \\ training loss: 0.00391041992150028 \\ validation loss: 1.6774423867464066\n",
      "--- 20.40045142173767 seconds ---\n",
      "iteration: 750 \\ training loss: 0.006428939769701923 \\ validation loss: 1.672826811671257\n",
      "--- 20.345595359802246 seconds ---\n",
      "iteration: 800 \\ training loss: 0.0027073885772979874 \\ validation loss: 1.6653704941272736\n",
      "--- 20.35167121887207 seconds ---\n",
      "model at iteration 800 is saved\n",
      "iteration: 850 \\ training loss: 0.003778128360863775 \\ validation loss: 1.654231309890747\n",
      "--- 20.34906554222107 seconds ---\n",
      "iteration: 900 \\ training loss: 0.0029537563027320977 \\ validation loss: 1.6585168838500977\n",
      "--- 20.346607208251953 seconds ---\n",
      "iteration: 950 \\ training loss: 0.00264273354482344 \\ validation loss: 1.6513957232236862\n",
      "--- 20.35754895210266 seconds ---\n",
      "iteration: 1000 \\ training loss: 0.002393978973165812 \\ validation loss: 1.6529594212770462\n",
      "--- 20.363548278808594 seconds ---\n",
      "model at iteration 1000 is saved\n",
      "iteration: 1050 \\ training loss: 0.0035488232456640724 \\ validation loss: 1.6431442648172379\n",
      "--- 20.32465147972107 seconds ---\n",
      "iteration: 1100 \\ training loss: 0.0022744120215065777 \\ validation loss: 1.6257024556398392\n",
      "--- 20.33961057662964 seconds ---\n",
      "iteration: 1150 \\ training loss: 0.0017129750220406363 \\ validation loss: 1.6315775364637375\n",
      "--- 20.457926511764526 seconds ---\n",
      "iteration: 1200 \\ training loss: 0.0013063517724410357 \\ validation loss: 1.6313335001468658\n",
      "--- 20.377525091171265 seconds ---\n",
      "model at iteration 1200 is saved\n",
      "iteration: 1250 \\ training loss: 0.0012275661694515934 \\ validation loss: 1.6255031824111938\n",
      "--- 20.33961009979248 seconds ---\n",
      "iteration: 1300 \\ training loss: 0.0018519413510255296 \\ validation loss: 1.6187048703432083\n",
      "--- 20.351120471954346 seconds ---\n",
      "iteration: 1350 \\ training loss: 0.002085199723403682 \\ validation loss: 1.6147798597812653\n",
      "--- 20.334624528884888 seconds ---\n",
      "iteration: 1400 \\ training loss: 0.0013686271490501787 \\ validation loss: 1.622099608182907\n",
      "--- 20.32365345954895 seconds ---\n",
      "model at iteration 1400 is saved\n",
      "iteration: 1450 \\ training loss: 0.0016319073705851812 \\ validation loss: 1.6099441200494766\n",
      "--- 20.37864089012146 seconds ---\n",
      "iteration: 1500 \\ training loss: 0.0010501369029310916 \\ validation loss: 1.6188907623291016\n",
      "--- 20.8328218460083 seconds ---\n",
      "iteration: 1550 \\ training loss: 0.0020757301844081238 \\ validation loss: 1.616956114768982\n",
      "--- 20.611883640289307 seconds ---\n",
      "iteration: 1600 \\ training loss: 0.0009006296947036925 \\ validation loss: 1.6182750016450882\n",
      "--- 20.66276788711548 seconds ---\n",
      "model at iteration 1600 is saved\n",
      "iteration: 1650 \\ training loss: 0.00101578063400024 \\ validation loss: 1.6134923100471497\n",
      "--- 20.579967737197876 seconds ---\n",
      "iteration: 1700 \\ training loss: 0.0018996385419193435 \\ validation loss: 1.6030340641736984\n",
      "--- 20.568001747131348 seconds ---\n",
      "iteration: 1750 \\ training loss: 0.0010294239370576927 \\ validation loss: 1.6085842549800873\n",
      "--- 20.9443142414093 seconds ---\n",
      "iteration: 1800 \\ training loss: 0.001045974760713494 \\ validation loss: 1.6087687015533447\n",
      "--- 23.35770869255066 seconds ---\n",
      "model at iteration 1800 is saved\n",
      "iteration: 1850 \\ training loss: 0.0006862043964621775 \\ validation loss: 1.59821817278862\n",
      "--- 21.270360708236694 seconds ---\n",
      "iteration: 1900 \\ training loss: 0.0014980956740841707 \\ validation loss: 1.5926471799612045\n",
      "--- 21.183617115020752 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from CustomDatasetPytorch import CustomAllLoadDataset\n",
    "\n",
    "from util import rescale, find_max_epoch, print_size\n",
    "from util import training_loss, calc_diffusion_hyperparams\n",
    "\n",
    "from distributed_util import init_distributed, apply_gradient_allreduce, reduce_tensor\n",
    "from torch.utils.data import random_split\n",
    "from WaveNet_regressor import WaveNet_regressor as WaveNet\n",
    "\n",
    "\n",
    "def train(window_length, hop_length, num_gpus, rank, group_name, output_directory, tensorboard_directory,\n",
    "          ckpt_iter, n_iters, iters_per_ckpt, iters_per_logging,\n",
    "          learning_rate, batch_size_per_gpu):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    num_gpus, rank, group_name:     parameters for distributed training\n",
    "    output_directory (str):         save model checkpoints to this path\n",
    "    tensorboard_directory (str):    save tensorboard events to this path\n",
    "    ckpt_iter (int or 'max'):       the pretrained checkpoint to be loaded;\n",
    "                                    automitically selects the maximum iteration if 'max' is selected\n",
    "    n_iters (int):                  number of iterations to train, default is 1M\n",
    "    iters_per_ckpt (int):           number of iterations to save checkpoint,\n",
    "                                    default is 10k, for models with residual_channel=64 this number can be larger\n",
    "    iters_per_logging (int):        number of iterations to save training log, default is 100\n",
    "    learning_rate (float):          learning rate\n",
    "    batch_size_per_gpu (int):       batchsize per gpu, default is 2 so total batchsize is 16 with 8 gpus\n",
    "    \"\"\"\n",
    "\n",
    "    # generate experiment (local) path\n",
    "    local_path = \"ch{}_wavRegressor\".format(wavenet_config[\"res_channels\"])\n",
    "    # Create tensorboard logger.\n",
    "    if rank == 0:\n",
    "        tb = SummaryWriter(os.path.join('exp', local_path, tensorboard_directory))\n",
    "\n",
    "    # distributed running initialization\n",
    "    if num_gpus > 1:\n",
    "        init_distributed(rank, num_gpus, group_name, **dist_config)\n",
    "\n",
    "    # Get shared output_directory ready\n",
    "    output_directory = os.path.join('exp', local_path, output_directory)\n",
    "    if rank == 0:\n",
    "        if not os.path.isdir(output_directory):\n",
    "            os.makedirs(output_directory)\n",
    "            os.chmod(output_directory, 0o775)\n",
    "        print(\"output directory\", output_directory, flush=True)\n",
    "\n",
    "    # map diffusion hyperparameters to gpu\n",
    "    # for key in diffusion_hyperparams:\n",
    "    #    if key is not \"T\":\n",
    "    #       diffusion_hyperparams[key] = diffusion_hyperparams[key].cuda()\n",
    "\n",
    "    # predefine model\n",
    "    net = WaveNet(**wavenet_config).cuda()\n",
    "    print_size(net)\n",
    "\n",
    "    # apply gradient all reduce\n",
    "    if num_gpus > 1:\n",
    "        net = apply_gradient_allreduce(net)\n",
    "\n",
    "    # define optimizer\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "    # load checkpoint\n",
    "    if ckpt_iter == 'max':\n",
    "        ckpt_iter = find_max_epoch(output_directory)\n",
    "    if ckpt_iter >= 0:\n",
    "        try:\n",
    "            # load checkpoint file\n",
    "            model_path = os.path.join(output_directory, '{}.pkl'.format(ckpt_iter))\n",
    "            checkpoint = torch.load(model_path, map_location='cpu')\n",
    "\n",
    "            # feed model dict and optimizer state\n",
    "            net.load_state_dict(checkpoint['model_state_dict'])\n",
    "            if 'optimizer_state_dict' in checkpoint:\n",
    "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "            print('Successfully loaded model at iteration {}'.format(ckpt_iter))\n",
    "        except:\n",
    "            ckpt_iter = -1\n",
    "            print('No valid checkpoint model found, start training from initialization.')\n",
    "    else:\n",
    "        ckpt_iter = -1\n",
    "        print('No valid checkpoint model found, start training from initialization.')\n",
    "\n",
    "    # Get the path to the config file\n",
    "    experiments_folder = \"C:/Users/YLY/Documents/eegAudChallenge/auditory-eeg-challenge-2023-code/task2_regression\"\n",
    "    task_folder = Path(experiments_folder)\n",
    "    config_path = task_folder / \"util/config.json\"\n",
    "\n",
    "    with open(config_path) as fp:\n",
    "        config = json.load(fp)\n",
    "\n",
    "    data_folder = Path(config[\"dataset_folder\"]) / config[\"split_folder\"]\n",
    "    stimulus_features = [\"envelope\"]\n",
    "    features = [\"eeg\"] + stimulus_features\n",
    "\n",
    "    train_files = [path for path in Path(data_folder).resolve().glob(\"train_-_*\") if\n",
    "                   path.stem.split(\"_-_\")[-1].split(\".\")[0] in features]\n",
    "    \n",
    "    valid_files = [path for path in Path(data_folder).resolve().glob(\"val_-_*\") if\n",
    "                   path.stem.split(\"_-_\")[-1].split(\".\")[0] in features]\n",
    "    \n",
    "    train_dataset = CustomAllLoadDataset(train_files, window_length, hop_length)\n",
    "    train_dataset.convertToTensorType()\n",
    "    \n",
    "    valid_dataset = CustomAllLoadDataset(valid_files, window_length, hop_length)\n",
    "    valid_dataset.convertToTensorType()\n",
    "    \n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    train_dataset.send_to_device(device)\n",
    "    valid_dataset.send_to_device(device)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    vali_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=64, shuffle=False)\n",
    "    \n",
    "    # training\n",
    "    n_iter = ckpt_iter + 1\n",
    "    mse_loss = nn.MSELoss()\n",
    "    while n_iter < n_iters + 1:\n",
    "        start_time = time.time()\n",
    "        batch_loss = 0\n",
    "        no_epoch = 0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            no_epoch = i\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            #eeg, audio = data[0].squeeze(1).cuda(), data[1].type(torch.LongTensor).cuda()\n",
    "            #eeg, audio = data[0].squeeze(1), data[1]\n",
    "            eeg, audio = data[0], data[1]\n",
    "            #print(eeg.shape,audio.shape)\n",
    "            # load audio and mel spectrogram\n",
    "            # mel_spectrogram = mel_spectrogram.cuda()\n",
    "            # audio = audio.unsqueeze(1).cuda()\n",
    "\n",
    "            # back-propagation\n",
    "            optimizer.zero_grad()\n",
    "            #X = (eeg, audio)\n",
    "            loss = mse_loss(net(eeg), audio)\n",
    "            batch_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # output to log\n",
    "            # note, only do this on the first gpu\n",
    "        if n_iter % iters_per_logging == 0 and rank == 0:\n",
    "            # save training loss to tensorboard\n",
    "            with torch.no_grad():\n",
    "                net.eval()     # Optional when not using Model Specific layer\n",
    "                valLoss = 0\n",
    "                no_valid_epoch = 0\n",
    "                for i, data in enumerate(vali_loader, 0):\n",
    "                    # get the inputs\n",
    "                    no_valid_epoch = i\n",
    "                    eeg, audio = data[0], data[1]\n",
    "                    # calc loss\n",
    "                    loss = mse_loss(net(eeg), audio)\n",
    "                    valLoss += loss.item()\n",
    "            \n",
    "            train_loss = batch_loss / no_epoch\n",
    "            val_loss = valLoss / no_valid_epoch\n",
    "            print(\"iteration: {} \\ training loss: {} \\ validation loss: {}\".format(n_iter, train_loss, val_loss))\n",
    "            print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "            tb.add_scalar(\"Log-Train-Loss\", np.log(train_loss), n_iter)\n",
    "            tb.add_scalar(\"Log-Validation-Loss\", np.log(val_loss), n_iter)\n",
    "\n",
    "        # save checkpoint\n",
    "        if n_iter > 0 and n_iter % iters_per_ckpt == 0 and rank == 0:\n",
    "            checkpoint_name = '{}.pkl'.format(n_iter)\n",
    "            torch.save({'model_state_dict': net.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict()},\n",
    "                       os.path.join(output_directory, checkpoint_name))\n",
    "            print('model at iteration %s is saved' % n_iter)\n",
    "\n",
    "        n_iter += 1\n",
    "        \n",
    "    # Close TensorBoard.\n",
    "    if rank == 0:\n",
    "        tb.close()\n",
    "\n",
    "\n",
    "\"\"\"Example experiment for a linear baseline method.\"\"\"\n",
    "import glob\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from torch.utils.data import DataLoader\n",
    "from task2_regression.models.linear import simple_linear_model\n",
    "from task2_regression.util.dataset_generator import RegressionDataGenerator, create_tf_dataset\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_dict):\n",
    "    \"\"\"Evaluate a model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: tf.keras.Model\n",
    "        Model to evaluate.\n",
    "    test_dict: dict\n",
    "        Mapping between a subject and a tf.data.Dataset containing the test\n",
    "        set for the subject.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Mapping between a subject and the loss/evaluation score on the test set\n",
    "    \"\"\"\n",
    "    evaluation = {}\n",
    "    for subject, ds_test in test_dict.items():\n",
    "        logging.info(f\"Scores for subject {subject}:\")\n",
    "        results = model.evaluate(ds_test, verbose=2)\n",
    "        metrics = model.metrics_names\n",
    "        evaluation[subject] = dict(zip(metrics, results))\n",
    "    return evaluation\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Parameters\n",
    "    # Length of the decision window\n",
    "    window_length = 5 * 64  # 5s\n",
    "    # Hop length between two consecutive decision windows\n",
    "    hop_length = int(64 * 0.5)  # 0.5 seconds\n",
    "    epochs = 100\n",
    "    patience = 5\n",
    "    batch_size = 1\n",
    "    only_evaluate = False\n",
    "    training_log_filename = \"training_log.csv\"\n",
    "    results_filename = 'eval.json'\n",
    "\n",
    "    # Get the path to the config file\n",
    "    experiments_folder = \"C:/Users/YLY/Documents/eegAudChallenge/auditory-eeg-challenge-2023-code/task2_regression\"\n",
    "    task_folder = Path(experiments_folder)\n",
    "    config_path = task_folder / \"util/config.json\"\n",
    "\n",
    "    # Load the config\n",
    "    with open(config_path) as fp:\n",
    "        config = json.load(fp)\n",
    "\n",
    "    # Provide the path of the dataset\n",
    "    # which is split already to train, val, test\n",
    "\n",
    "    data_folder = os.path.join(config[\"dataset_folder\"], config[\"split_folder\"])\n",
    "    stimulus_features = [\"envelope\"]\n",
    "    features = [\"eeg\"] + stimulus_features\n",
    "\n",
    "    # Create a directory to store (intermediate) results\n",
    "    results_folder = os.path.join(experiments_folder, \"results_linear_baseline\")\n",
    "    os.makedirs(results_folder, exist_ok=True)\n",
    "\n",
    "    # create a simple linear model\n",
    "    # model = simple_linear_model()\n",
    "    # model.summary()\n",
    "    # model_path = os.path.join(results_folder, \"model.h5\")\n",
    "\n",
    "    if only_evaluate:\n",
    "        #    model = tf.keras.models.load_model(model_path)\n",
    "        print(\"evaluate\")\n",
    "    else:\n",
    "\n",
    "        # train_files = [x for x in glob.glob(os.path.join(data_folder, \"train_-_*\")) if os.path.basename(x).split(\"_-_\")[-1].split(\".\")[0] in features]\n",
    "        # Create list of numpy array files\n",
    "        # train_generator = RegressionDataGenerator(train_files, window_length)\n",
    "        # dataset_train = create_tf_dataset(train_generator, window_length, None, hop_length, batch_size)\n",
    "\n",
    "        # Create the generator for the validation set\n",
    "        # val_files = [x for x in glob.glob(os.path.join(data_folder, \"val_-_*\")) if os.path.basename(x).split(\"_-_\")[-1].split(\".\")[0] in features]\n",
    "        # val_generator = RegressionDataGenerator(val_files, window_length)\n",
    "        # dataset_val = create_tf_dataset(val_generator, window_length, None, hop_length, batch_size)\n",
    "        # Convert the TensorFlow dataset to a PyTorch dataset\n",
    "        # train_dataset= CustomDataset(dataset_train,340585)\n",
    "        # del dataset_train\n",
    "        # val_dataset = CustomDataset(dataset_val,38357)\n",
    "        # del dataset_val\n",
    "        #### train the model\n",
    "        # Parse configs. Globals nicer in this case\n",
    "        with open('waveNet-regressor.json') as f:\n",
    "            data = f.read()\n",
    "        config = json.loads(data)\n",
    "        train_config = config[\"train_config\"]  # training parameters\n",
    "        global dist_config\n",
    "        dist_config = config[\"dist_config\"]  # to initialize distributed training\n",
    "        global wavenet_config\n",
    "        wavenet_config = config[\"wavenet_config\"]  # to define wavenet\n",
    "        # global diffusion_config\n",
    "        # diffusion_config = config[\"diffusion_config\"]  # basic hyperparameters\n",
    "        global trainset_config\n",
    "        trainset_config = config[\"trainset_config\"]  # to load trainset\n",
    "        # global diffusion_hyperparams\n",
    "        # diffusion_hyperparams = calc_diffusion_hyperparams(\n",
    "        #    **diffusion_config)  # dictionary of all diffusion hyperparameters\n",
    "\n",
    "        torch.backends.cudnn.enabled = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        train(window_length, hop_length, 1, 0, \"test\", **train_config)\n",
    "\n",
    "    # Evaluate the model on test set\n",
    "    # Create a dataset generator for each test subject\n",
    "    # test_files = [x for x in glob.glob(os.path.join(data_folder, \"test_-_*\")) if os.path.basename(x).split(\"_-_\")[-1].split(\".\")[0] in features]\n",
    "    # Get all different subjects from the test set\n",
    "    # subjects = list(set([os.path.basename(x).split(\"_-_\")[1] for x in test_files]))\n",
    "    # datasets_test = {}\n",
    "    # Create a generator for each subject\n",
    "    # for sub in subjects:\n",
    "    #    files_test_sub = [f for f in test_files if sub in os.path.basename(f)]\n",
    "    #    test_generator = RegressionDataGenerator(files_test_sub, window_length)\n",
    "    #    datasets_test[sub] = create_tf_dataset(test_generator, window_length, None, hop_length, 1)\n",
    "\n",
    "    # Evaluate the model\n",
    "    # evaluation = evaluate_model(model, datasets_test)\n",
    "\n",
    "    # We can save our results in a json encoded file\n",
    "    # results_path = os.path.join(results_folder, results_filename)\n",
    "    # with open(results_path, \"w\") as fp:\n",
    "    #    json.dump(evaluation, fp)\n",
    "    # logging.info(f\"Results saved at {results_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7ef2b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
