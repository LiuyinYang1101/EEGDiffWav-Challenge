{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "654ff0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output directory exp\\ch128_wavRegressor\\logs/checkpoint\n",
      "WaveNet_regressor Parameters: 3.988097M\n",
      "No valid checkpoint model found, start training from initialization.\n",
      "508  files loaded.  229547  training examples loaded  254  files sent to GPU, with total data number:  114486\n",
      "508  files loaded.  28026  training examples loaded  254  files sent to GPU, with total data number:  14051\n",
      "first half data finished  254  files sent to GPU, with total data number:  115061\n",
      "finish one iteration  254  files sent to GPU, with total data number:  114457\n",
      "first half data finished  254  files sent to GPU, with total data number:  13975\n",
      "finish one iteration  254  files sent to GPU, with total data number:  13985\n",
      "iteration: 0 \\ training loss: 0.9793910631173427 \\ validation loss: 0.985668432794392\n",
      "--- 680.3424046039581 seconds ---\n",
      "first half data finished  254  files sent to GPU, with total data number:  115090\n",
      "finish one iteration  254  files sent to GPU, with total data number:  112242\n",
      "first half data finished  254  files sent to GPU, with total data number:  14041\n",
      "finish one iteration  254  files sent to GPU, with total data number:  14001\n",
      "iteration: 1 \\ training loss: 0.9706582662551282 \\ validation loss: 0.9807646068610097\n",
      "--- 678.219300031662 seconds ---\n",
      "model at iteration 1 is saved\n",
      " "
     ]
    }
   ],
   "source": [
    "%%prun\n",
    "import os\n",
    "import argparse\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from CustomDatasetPytorch import CustomProcessInOrderDataset\n",
    "\n",
    "from util import rescale, find_max_epoch, print_size\n",
    "from util import training_loss, calc_diffusion_hyperparams\n",
    "\n",
    "from distributed_util import init_distributed, apply_gradient_allreduce, reduce_tensor\n",
    "from torch.utils.data import random_split\n",
    "from WaveNet_regressor import WaveNet_regressor as WaveNet\n",
    "\n",
    "\n",
    "def train(window_length, hop_length, num_gpus, rank, group_name, output_directory, tensorboard_directory,\n",
    "          ckpt_iter, n_iters, iters_per_ckpt, iters_per_logging,\n",
    "          learning_rate, batch_size_per_gpu):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    num_gpus, rank, group_name:     parameters for distributed training\n",
    "    output_directory (str):         save model checkpoints to this path\n",
    "    tensorboard_directory (str):    save tensorboard events to this path\n",
    "    ckpt_iter (int or 'max'):       the pretrained checkpoint to be loaded;\n",
    "                                    automitically selects the maximum iteration if 'max' is selected\n",
    "    n_iters (int):                  number of iterations to train, default is 1M\n",
    "    iters_per_ckpt (int):           number of iterations to save checkpoint,\n",
    "                                    default is 10k, for models with residual_channel=64 this number can be larger\n",
    "    iters_per_logging (int):        number of iterations to save training log, default is 100\n",
    "    learning_rate (float):          learning rate\n",
    "    batch_size_per_gpu (int):       batchsize per gpu, default is 2 so total batchsize is 16 with 8 gpus\n",
    "    \"\"\"\n",
    "\n",
    "    # generate experiment (local) path\n",
    "    local_path = \"ch{}_wavRegressor\".format(wavenet_config[\"res_channels\"])\n",
    "    # Create tensorboard logger.\n",
    "    if rank == 0:\n",
    "        tb = SummaryWriter(os.path.join('exp', local_path, tensorboard_directory))\n",
    "\n",
    "    # distributed running initialization\n",
    "    if num_gpus > 1:\n",
    "        init_distributed(rank, num_gpus, group_name, **dist_config)\n",
    "\n",
    "    # Get shared output_directory ready\n",
    "    output_directory = os.path.join('exp', local_path, output_directory)\n",
    "    if rank == 0:\n",
    "        if not os.path.isdir(output_directory):\n",
    "            os.makedirs(output_directory)\n",
    "            os.chmod(output_directory, 0o775)\n",
    "        print(\"output directory\", output_directory, flush=True)\n",
    "\n",
    "    # map diffusion hyperparameters to gpu\n",
    "    # for key in diffusion_hyperparams:\n",
    "    #    if key is not \"T\":\n",
    "    #       diffusion_hyperparams[key] = diffusion_hyperparams[key].cuda()\n",
    "\n",
    "    # predefine model\n",
    "    net = WaveNet(**wavenet_config).cuda()\n",
    "    print_size(net)\n",
    "\n",
    "    # apply gradient all reduce\n",
    "    if num_gpus > 1:\n",
    "        net = apply_gradient_allreduce(net)\n",
    "\n",
    "    # define optimizer\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "    # load checkpoint\n",
    "    if ckpt_iter == 'max':\n",
    "        ckpt_iter = find_max_epoch(output_directory)\n",
    "    if ckpt_iter >= 0:\n",
    "        try:\n",
    "            # load checkpoint file\n",
    "            model_path = os.path.join(output_directory, '{}.pkl'.format(ckpt_iter))\n",
    "            checkpoint = torch.load(model_path, map_location='cpu')\n",
    "\n",
    "            # feed model dict and optimizer state\n",
    "            net.load_state_dict(checkpoint['model_state_dict'])\n",
    "            if 'optimizer_state_dict' in checkpoint:\n",
    "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "            print('Successfully loaded model at iteration {}'.format(ckpt_iter))\n",
    "        except:\n",
    "            ckpt_iter = -1\n",
    "            print('No valid checkpoint model found, start training from initialization.')\n",
    "    else:\n",
    "        ckpt_iter = -1\n",
    "        print('No valid checkpoint model found, start training from initialization.')\n",
    "\n",
    "    # Get the path to the config file\n",
    "    experiments_folder = \"C:/Users/YLY/Documents/eegAudChallenge/auditory-eeg-challenge-2023-code/task2_regression\"\n",
    "    task_folder = Path(experiments_folder)\n",
    "    config_path = task_folder / \"util/config.json\"\n",
    "\n",
    "    with open(config_path) as fp:\n",
    "        config = json.load(fp)\n",
    "\n",
    "    data_folder = Path(config[\"dataset_folder\"]) / config[\"split_folder\"]\n",
    "    stimulus_features = [\"envelope\"]\n",
    "    features = [\"eeg\"] + stimulus_features\n",
    "\n",
    "    train_files = [path for path in Path(data_folder).resolve().glob(\"train_-_*\") if\n",
    "                   path.stem.split(\"_-_\")[-1].split(\".\")[0] in features]\n",
    "    \n",
    "    valid_files = [path for path in Path(data_folder).resolve().glob(\"val_-_*\") if\n",
    "                   path.stem.split(\"_-_\")[-1].split(\".\")[0] in features]\n",
    "    \n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    train_dataset = CustomProcessInOrderDataset(train_files, window_length, hop_length, device)\n",
    "    \n",
    "    valid_dataset = CustomProcessInOrderDataset(valid_files, window_length, hop_length, device)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "    vali_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=64, shuffle=False)\n",
    "    \n",
    "    # training\n",
    "    n_iter = ckpt_iter + 1\n",
    "    mse_loss = nn.MSELoss()\n",
    "    while n_iter < n_iters + 1:\n",
    "        start_time = time.time()\n",
    "        batch_loss = 0\n",
    "        no_epoch = 0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            no_epoch = i\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            #eeg, audio = data[0].squeeze(1).cuda(), data[1].type(torch.LongTensor).cuda()\n",
    "            #eeg, audio = data[0].squeeze(1), data[1]\n",
    "            eeg, audio = data[0], data[1]\n",
    "            #print(eeg.shape,audio.shape)\n",
    "            # load audio and mel spectrogram\n",
    "            # mel_spectrogram = mel_spectrogram.cuda()\n",
    "            # audio = audio.unsqueeze(1).cuda()\n",
    "\n",
    "            # back-propagation\n",
    "            optimizer.zero_grad()\n",
    "            #X = (eeg, audio)\n",
    "            loss = mse_loss(net(eeg), audio)\n",
    "            batch_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # output to log\n",
    "            # note, only do this on the first gpu\n",
    "        if n_iter % iters_per_logging == 0 and rank == 0:\n",
    "            # save training loss to tensorboard\n",
    "            with torch.no_grad():\n",
    "                net.eval()     # Optional when not using Model Specific layer\n",
    "                valLoss = 0\n",
    "                no_valid_epoch = 0\n",
    "                for i, data in enumerate(vali_loader, 0):\n",
    "                    # get the inputs\n",
    "                    no_valid_epoch = i\n",
    "                    eeg, audio = data[0], data[1]\n",
    "                    # calc loss\n",
    "                    loss = mse_loss(net(eeg), audio)\n",
    "                    valLoss += loss.item()\n",
    "            \n",
    "            train_loss = batch_loss / no_epoch\n",
    "            val_loss = valLoss / no_valid_epoch\n",
    "            print(\"iteration: {} \\ training loss: {} \\ validation loss: {}\".format(n_iter, train_loss, val_loss))\n",
    "            print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "            tb.add_scalar(\"Log-Train-Loss\", np.log(train_loss), n_iter)\n",
    "            tb.add_scalar(\"Log-Validation-Loss\", np.log(val_loss), n_iter)\n",
    "\n",
    "        # save checkpoint\n",
    "        if n_iter > 0 and n_iter % iters_per_ckpt == 0 and rank == 0:\n",
    "            checkpoint_name = '{}.pkl'.format(n_iter)\n",
    "            torch.save({'model_state_dict': net.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict()},\n",
    "                       os.path.join(output_directory, checkpoint_name))\n",
    "            print('model at iteration %s is saved' % n_iter)\n",
    "\n",
    "        n_iter += 1\n",
    "        \n",
    "    # Close TensorBoard.\n",
    "    if rank == 0:\n",
    "        tb.close()\n",
    "\n",
    "\n",
    "\"\"\"Example experiment for a linear baseline method.\"\"\"\n",
    "import glob\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from torch.utils.data import DataLoader\n",
    "from task2_regression.models.linear import simple_linear_model\n",
    "from task2_regression.util.dataset_generator import RegressionDataGenerator, create_tf_dataset\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_dict):\n",
    "    \"\"\"Evaluate a model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: tf.keras.Model\n",
    "        Model to evaluate.\n",
    "    test_dict: dict\n",
    "        Mapping between a subject and a tf.data.Dataset containing the test\n",
    "        set for the subject.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Mapping between a subject and the loss/evaluation score on the test set\n",
    "    \"\"\"\n",
    "    evaluation = {}\n",
    "    for subject, ds_test in test_dict.items():\n",
    "        logging.info(f\"Scores for subject {subject}:\")\n",
    "        results = model.evaluate(ds_test, verbose=2)\n",
    "        metrics = model.metrics_names\n",
    "        evaluation[subject] = dict(zip(metrics, results))\n",
    "    return evaluation\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Parameters\n",
    "    # Length of the decision window\n",
    "    window_length = 3 * 64  # 3s\n",
    "    # Hop length between two consecutive decision windows\n",
    "    hop_length = int(64 * 1.5)  # 1.5 seconds\n",
    "    epochs = 100\n",
    "    patience = 5\n",
    "    batch_size = 1\n",
    "    only_evaluate = False\n",
    "    training_log_filename = \"training_log.csv\"\n",
    "    results_filename = 'eval.json'\n",
    "\n",
    "    # Get the path to the config file\n",
    "    experiments_folder = \"C:/Users/YLY/Documents/eegAudChallenge/auditory-eeg-challenge-2023-code/task2_regression\"\n",
    "    task_folder = Path(experiments_folder)\n",
    "    config_path = task_folder / \"util/config.json\"\n",
    "\n",
    "    # Load the config\n",
    "    with open(config_path) as fp:\n",
    "        config = json.load(fp)\n",
    "\n",
    "    # Provide the path of the dataset\n",
    "    # which is split already to train, val, test\n",
    "\n",
    "    data_folder = os.path.join(config[\"dataset_folder\"], config[\"split_folder\"])\n",
    "    stimulus_features = [\"envelope\"]\n",
    "    features = [\"eeg\"] + stimulus_features\n",
    "\n",
    "    # Create a directory to store (intermediate) results\n",
    "    results_folder = os.path.join(experiments_folder, \"results_linear_baseline\")\n",
    "    os.makedirs(results_folder, exist_ok=True)\n",
    "\n",
    "    # create a simple linear model\n",
    "    # model = simple_linear_model()\n",
    "    # model.summary()\n",
    "    # model_path = os.path.join(results_folder, \"model.h5\")\n",
    "\n",
    "    if only_evaluate:\n",
    "        #    model = tf.keras.models.load_model(model_path)\n",
    "        print(\"evaluate\")\n",
    "    else:\n",
    "\n",
    "        # train_files = [x for x in glob.glob(os.path.join(data_folder, \"train_-_*\")) if os.path.basename(x).split(\"_-_\")[-1].split(\".\")[0] in features]\n",
    "        # Create list of numpy array files\n",
    "        # train_generator = RegressionDataGenerator(train_files, window_length)\n",
    "        # dataset_train = create_tf_dataset(train_generator, window_length, None, hop_length, batch_size)\n",
    "\n",
    "        # Create the generator for the validation set\n",
    "        # val_files = [x for x in glob.glob(os.path.join(data_folder, \"val_-_*\")) if os.path.basename(x).split(\"_-_\")[-1].split(\".\")[0] in features]\n",
    "        # val_generator = RegressionDataGenerator(val_files, window_length)\n",
    "        # dataset_val = create_tf_dataset(val_generator, window_length, None, hop_length, batch_size)\n",
    "        # Convert the TensorFlow dataset to a PyTorch dataset\n",
    "        # train_dataset= CustomDataset(dataset_train,340585)\n",
    "        # del dataset_train\n",
    "        # val_dataset = CustomDataset(dataset_val,38357)\n",
    "        # del dataset_val\n",
    "        #### train the model\n",
    "        # Parse configs. Globals nicer in this case\n",
    "        with open('waveNet-regressor.json') as f:\n",
    "            data = f.read()\n",
    "        config = json.loads(data)\n",
    "        train_config = config[\"train_config\"]  # training parameters\n",
    "        global dist_config\n",
    "        dist_config = config[\"dist_config\"]  # to initialize distributed training\n",
    "        global wavenet_config\n",
    "        wavenet_config = config[\"wavenet_config\"]  # to define wavenet\n",
    "        # global diffusion_config\n",
    "        # diffusion_config = config[\"diffusion_config\"]  # basic hyperparameters\n",
    "        global trainset_config\n",
    "        trainset_config = config[\"trainset_config\"]  # to load trainset\n",
    "        # global diffusion_hyperparams\n",
    "        # diffusion_hyperparams = calc_diffusion_hyperparams(\n",
    "        #    **diffusion_config)  # dictionary of all diffusion hyperparameters\n",
    "\n",
    "        torch.backends.cudnn.enabled = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        train(window_length, hop_length, 1, 0, \"test\", **train_config)\n",
    "\n",
    "    # Evaluate the model on test set\n",
    "    # Create a dataset generator for each test subject\n",
    "    # test_files = [x for x in glob.glob(os.path.join(data_folder, \"test_-_*\")) if os.path.basename(x).split(\"_-_\")[-1].split(\".\")[0] in features]\n",
    "    # Get all different subjects from the test set\n",
    "    # subjects = list(set([os.path.basename(x).split(\"_-_\")[1] for x in test_files]))\n",
    "    # datasets_test = {}\n",
    "    # Create a generator for each subject\n",
    "    # for sub in subjects:\n",
    "    #    files_test_sub = [f for f in test_files if sub in os.path.basename(f)]\n",
    "    #    test_generator = RegressionDataGenerator(files_test_sub, window_length)\n",
    "    #    datasets_test[sub] = create_tf_dataset(test_generator, window_length, None, hop_length, 1)\n",
    "\n",
    "    # Evaluate the model\n",
    "    # evaluation = evaluate_model(model, datasets_test)\n",
    "\n",
    "    # We can save our results in a json encoded file\n",
    "    # results_path = os.path.join(results_folder, results_filename)\n",
    "    # with open(results_path, \"w\") as fp:\n",
    "    #    json.dump(evaluation, fp)\n",
    "    # logging.info(f\"Results saved at {results_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7ef2b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
