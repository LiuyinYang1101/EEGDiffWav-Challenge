{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20dda646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508  files loaded.  229547  training examples loaded\n",
      "total:  229504 torch.Size([43, 64, 192]) torch.Size([43, 1, 192])\n",
      "--- 479.3682773113251 seconds ---\n",
      " "
     ]
    }
   ],
   "source": [
    "%%prun\n",
    "import glob\n",
    "import json\n",
    "from pathlib import Path\n",
    "from CustomDatasetPytorch import CustomAllLoadDataset\n",
    "import torch\n",
    "import time\n",
    " # Get the path to the config file\n",
    "experiments_folder = \"C:/Users/YLY/Documents/eegAudChallenge/auditory-eeg-challenge-2023-code/task2_regression\"\n",
    "task_folder = Path(experiments_folder)\n",
    "config_path = task_folder/ \"util/config.json\"\n",
    "    \n",
    "with open(config_path) as fp:\n",
    "    config = json.load(fp)\n",
    "\n",
    "data_folder = Path(config[\"dataset_folder\"])/ config[\"split_folder\"]\n",
    "stimulus_features = [\"envelope\"]\n",
    "features = [\"eeg\"] + stimulus_features\n",
    "\n",
    "train_files = [path for path in Path(data_folder).resolve().glob(\"train_-_*\") if path.stem.split(\"_-_\")[-1].split(\".\")[0] in features]\n",
    "\n",
    "train_dataset = CustomAllLoadDataset(train_files,64*3,int(64*1.5))\n",
    "train_dataset.convertToTensorType()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "train_dataset.send_to_device(device,0.7)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=64,shuffle=True)\n",
    "\n",
    "start_time = time.time()\n",
    "for ite in range(1):\n",
    "    \n",
    "    count = 0\n",
    "    for batch in dataloader:\n",
    "        count+=1\n",
    "print(\"total: \", (count-1)*64,batch[0].shape,batch[1].shape)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64e1d222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from random import randrange\n",
    "import torchaudio.transforms as T\n",
    "import torch\n",
    "\n",
    "class CustomAllLoadRawWaveDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, filePaths, frameLength, hopSize, resample_rate):\n",
    "        self.filePaths = filePaths\n",
    "        self.frameLength = frameLength\n",
    "        self.hopSize = hopSize\n",
    "        self.resample_rate = resample_rate\n",
    "        self.filePage = len(self.filePaths)\n",
    "        # load all data to memory as continuous data\n",
    "        self.AudioData = []\n",
    "        self.loadDataToBuffer()\n",
    "\n",
    "        self.sampleIndxMap = []\n",
    "        self.noData = self.generateSamplePostion()\n",
    "        print(\"data load finished: \", self.filePage, \" files in total \", self.noData, \" samples in total\")\n",
    "\n",
    "    def loadDataToBuffer(self):\n",
    "        for i in range(self.filePage):\n",
    "            b = np.load(self.filePaths[i])\n",
    "            data = torch.from_numpy(b['audio'])\n",
    "            sample_rate = b['fs']\n",
    "            resampler = T.Resample(sample_rate, self.resample_rate, dtype=data.dtype)\n",
    "            resampled_waveform = resampler(data)\n",
    "            print(\"file \", i, \"from: \", data.shape[0], \"to \", resampled_waveform.shape[0])\n",
    "            self.AudioData.append(resampled_waveform)\n",
    "\n",
    "    def generateSamplePostion(self):\n",
    "        count = 0\n",
    "        for i in range(self.filePage):\n",
    "            totalLength = self.AudioData[i].shape[0]\n",
    "            startPos = [*range(self.frameLength, totalLength + 1, self.hopSize)]\n",
    "            for pos in startPos:\n",
    "                self.sampleIndxMap.append((i, pos))\n",
    "            noData = (totalLength - self.frameLength) // self.hopSize + 1\n",
    "            assert len(startPos) == noData\n",
    "            print(\"file \", i, \"load: \", noData)\n",
    "            count += noData\n",
    "        return count\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.noData\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return np.array([[[0], [1], [2]]]), torch.unsqueeze(self.AudioData[self.sampleIndxMap[idx][0]][self.sampleIndxMap[idx][1] - self.frameLength:self.sampleIndxMap[idx][1]],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbfd3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the config\n",
    "with open(\"C:/Users/YLY/Documents/eegAudChallenge/auditory-eeg-challenge-2023-code/task2_regression/util/config.json\") as fp:\n",
    "    config = json.load(fp)\n",
    "\n",
    "# Provide the path of the dataset\n",
    "# which is split already to train, val, test\n",
    "\n",
    "data_folder = Path(config[\"dataset_folder\"])/config[\"raw_stimuli_folder\"]\n",
    "train_files = [path for path in Path(data_folder).resolve().glob(\"*.npz\") if path.stem.split(\"_\")[1] == \"1\"]\n",
    "print(len(train_files))\n",
    "b = np.load(train_files[3])\n",
    "data = torch.from_numpy(b['audio'])\n",
    "sample_rate = b['fs']\n",
    "resampler = T.Resample(sample_rate, 11600, dtype=data.dtype)\n",
    "resampled_waveform = resampler(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6515ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "Audio(resampled_waveform, rate=11600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aca7c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_dataset.__getitem__(2300)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381a44ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "Audio(data, rate=11600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755e31e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(1)\n",
    "\n",
    "plot_a = plt.subplot(211)\n",
    "plot_a.plot(data.squeeze())\n",
    "plot_a.set_xlabel('sample rate * time')\n",
    "plot_a.set_ylabel('energy')\n",
    "\n",
    "plot_b = plt.subplot(212)\n",
    "plot_b.specgram(data.squeeze(), NFFT=1024, Fs=11600, noverlap=512)\n",
    "plot_b.set_xlabel('Time')\n",
    "plot_b.set_ylabel('Frequency')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e091303d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the config\n",
    "with open(\"C:/Users/YLY/Documents/eegAudChallenge/auditory-eeg-challenge-2023-code/task2_regression/util/config.json\") as fp:\n",
    "    config = json.load(fp)\n",
    "\n",
    "# Provide the path of the dataset\n",
    "# which is split already to train, val, test\n",
    "\n",
    "data_folder = Path(config[\"dataset_folder\"])/config[\"raw_stimuli_folder\"]\n",
    "train_files = [path for path in Path(data_folder).resolve().glob(\"*.npz\") if path.stem.split(\"_\")[1] == \"1\"]\n",
    "print(train_files[0])\n",
    "b = np.load(train_files[0])\n",
    "data = torch.from_numpy(b['audio'])\n",
    "print(data.shape)\n",
    "print(b['fs'])\n",
    "sample_rate = b['fs']\n",
    "resampler = T.Resample(sample_rate, 11600, dtype=data.dtype)\n",
    "resampled_waveform = resampler(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64a0db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the config\n",
    "with open(\"C:/Users/YLY/Documents/eegAudChallenge/auditory-eeg-challenge-2023-code/task2_regression/util/config.json\") as fp:\n",
    "    config = json.load(fp)\n",
    "\n",
    "# Provide the path of the dataset\n",
    "# which is split already to train, val, test\n",
    "\n",
    "data_folder = Path(config[\"dataset_folder\"])/config[\"raw_eeg_folder\"]\n",
    "train_files = [path for path in Path(data_folder).resolve().glob(\"*.pkl\")]\n",
    "print(len(train_files))\n",
    "import pickle\n",
    "\n",
    "\n",
    "with open(train_files[2], 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    print(data['eeg'].shape)\n",
    "    print(data['fs'])\n",
    "    print(data['subject'])\n",
    "    print(data['stimulus'])\n",
    "    print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58ead5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['eeg'].shape)\n",
    "print(data['fs'])\n",
    "print(data['subject'])\n",
    "print(data['stimulus'])\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6239ffd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
