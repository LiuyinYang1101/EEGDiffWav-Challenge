{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2696ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from random import randrange\n",
    "    \n",
    "###Test Streaming DataLoader with PyTorch####\n",
    "class MyIterableDataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, filePaths, frameLength, hopSize):\n",
    "            super(MyIterableDataset).__init__()\n",
    "            self.filePaths = self.group_recordings(filePaths)\n",
    "            self.frameLength = frameLength\n",
    "            self.hopSize = hopSize\n",
    "            self.filePage = len(self.filePaths)\n",
    "            self.filePool = list(range(self.filePage))\n",
    "            random.shuffle(self.filePool)\n",
    "\n",
    "            self.currentFileIndx = 0\n",
    "            self.CurrentEEG = []\n",
    "            self.CurrentAudio = []\n",
    "            self.samplePosistions = []\n",
    "\n",
    "            self.currentSampleIndex = 0\n",
    "            self.loadDataToBuffer(self.currentFileIndx)\n",
    "            \n",
    "            self.samplePosMap = []\n",
    "            self.generateSamplePostion()\n",
    "            \n",
    "    def group_recordings(self, files):\n",
    "        #Group recordings and corresponding stimuli.\n",
    "        new_files = []\n",
    "        grouped = itertools.groupby(sorted(files), lambda x: \"_-_\".join(x.stem.split(\"_-_\")[:3]))\n",
    "        for recording_name, feature_paths in grouped:\n",
    "            new_files += [sorted(feature_paths, key=lambda x: \"0\" if x == \"eeg\" else x)]\n",
    "        return new_files    \n",
    "    import random\n",
    "    \n",
    "    def loadDataToBuffer(self,fileIndex):\n",
    "        self.CurrentEEG = np.load(self.filePaths[self.filePool[self.currentFileIndx]][0]).astype(np.float32)\n",
    "        self.CurrentAudio = np.load(self.filePaths[self.filePool[self.currentFileIndx]][1]).astype(np.float32)\n",
    "\n",
    "    \n",
    "    def generateSamplePostion(self):\n",
    "        count = 0\n",
    "        for i in range(self.filePage):\n",
    "            tempAudio = np.load(self.filePaths[i][1]).astype(np.float32)\n",
    "            totalLength,_ = tempAudio.shape\n",
    "            startPos = [*range(self.frameLength, totalLength+1, self.hopSize)]\n",
    "            self.samplePosMap.append(startPos)\n",
    "            noData = (totalLength-self.frameLength)//self.hopSize + 1\n",
    "            assert len(startPos)==noData\n",
    "            count += noData\n",
    "        return count\n",
    "    def sample_random_data_number_in_one_batch(self,n, total):\n",
    "    #Return a randomly chosen list of n nonnegative integers summing to total.\n",
    "    #n: the number of total files    total: batch size\n",
    "        return [x - 1 for x in self.constrained_sum_sample_pos(n, total + n)]\n",
    "    \n",
    "    def constrained_sum_sample_pos(self,n, total):\n",
    "    #Return a randomly chosen list of n positive integers summing to total.Each such list is equally likely to occur.\"\"\"\n",
    "        dividers = sorted(random.sample(range(1, total), n - 1))\n",
    "        return [a - b for a, b in zip(dividers + [total], [0] + dividers)]\n",
    "            \n",
    "    def __iter__(self):\n",
    "       \n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.currentSampleIndex < len(self.samplePosMap[self.filePool[self.currentFileIndx]]): # still in the same file\n",
    "            thisEnd = self.samplePosMap[self.filePool[self.currentFileIndx]][self.currentSampleIndex]\n",
    "            self.currentSampleIndex += 1\n",
    "            return self.CurrentEEG[thisEnd-self.frameLength:thisEnd,:], self.CurrentAudio[thisEnd-self.frameLength:thisEnd,:]\n",
    "        else: # move to the next file\n",
    "            #print(\"next file\")\n",
    "            #### need to shuffle samples from the last file\n",
    "            random.shuffle(self.samplePosMap[self.filePool[self.currentFileIndx]])\n",
    "            self.currentFileIndx +=1\n",
    "            self.currentSampleIndex = 0\n",
    "            if self.currentFileIndx < self.filePage: # still in the same iteration\n",
    "                self.loadDataToBuffer(self.currentFileIndx)\n",
    "                thisEnd = self.samplePosMap[self.filePool[self.currentFileIndx]][self.currentSampleIndex]\n",
    "                self.currentSampleIndex += 1\n",
    "                return self.CurrentEEG[thisEnd-self.frameLength:thisEnd,:], self.CurrentAudio[thisEnd-self.frameLength:thisEnd,:]\n",
    "            else:\n",
    "                #print(\"here 2\")\n",
    "                random.shuffle(self.filePool)\n",
    "                self.currentFileIndx = 0\n",
    "                self.loadDataToBuffer(self.currentFileIndx)\n",
    "                raise StopIteration\n",
    "                print(\"iteration done, restart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d74c6066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  340544 tensor(1.3223) tensor([-0.4877])\n",
      "--- 28.135335445404053 seconds ---\n",
      "total:  340544 tensor(0.8434) tensor([-0.9459])\n",
      "--- 34.69516396522522 seconds ---\n",
      "total:  340544 tensor(-1.2050) tensor([-0.1638])\n",
      "--- 37.483428716659546 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    " # Get the path to the config file\n",
    "experiments_folder = \"C:/Users/YLY/Documents/eegAudChallenge/auditory-eeg-challenge-2023-code/task2_regression\"\n",
    "task_folder = Path(experiments_folder)\n",
    "config_path = task_folder/ \"util/config.json\"\n",
    "    \n",
    "with open(config_path) as fp:\n",
    "    config = json.load(fp)\n",
    "\n",
    "data_folder = Path(config[\"dataset_folder\"])/ config[\"split_folder\"]\n",
    "stimulus_features = [\"envelope\"]\n",
    "features = [\"eeg\"] + stimulus_features\n",
    "\n",
    "train_files = [path for path in Path(data_folder).resolve().glob(\"train_-_*\") if path.stem.split(\"_-_\")[-1].split(\".\")[0] in features]\n",
    "\n",
    "train_dataset = MyIterableDataset(train_files,64*10,64)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=64,shuffle=False)\n",
    "\n",
    "for ite in range(3):\n",
    "    start_time = time.time()\n",
    "    count = 0\n",
    "    for batch in dataloader:\n",
    "        count+=1\n",
    "    print(\"total: \", (count-1)*64,batch[0][1,1,1],batch[1][1][1])\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20dda646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([41, 640, 64])\n"
     ]
    }
   ],
   "source": [
    "print(batch[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e1d222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbfd3fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
