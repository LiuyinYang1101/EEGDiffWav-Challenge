{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfe157bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:58: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "<>:58: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "from util import rescale, find_max_epoch, print_size\n",
    "from util import training_loss, calc_diffusion_hyperparams\n",
    "\n",
    "from distributed_util import init_distributed, apply_gradient_allreduce, reduce_tensor\n",
    "\n",
    "from models2 import EEGWav_diff as WaveNet\n",
    "\n",
    "def train(train_loader, num_gpus, rank, group_name, output_directory, tensorboard_directory,\n",
    "          ckpt_iter, n_iters, iters_per_ckpt, iters_per_logging,\n",
    "          learning_rate, batch_size_per_gpu):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    num_gpus, rank, group_name:     parameters for distributed training\n",
    "    output_directory (str):         save model checkpoints to this path\n",
    "    tensorboard_directory (str):    save tensorboard events to this path\n",
    "    ckpt_iter (int or 'max'):       the pretrained checkpoint to be loaded;\n",
    "                                    automitically selects the maximum iteration if 'max' is selected\n",
    "    n_iters (int):                  number of iterations to train, default is 1M\n",
    "    iters_per_ckpt (int):           number of iterations to save checkpoint,\n",
    "                                    default is 10k, for models with residual_channel=64 this number can be larger\n",
    "    iters_per_logging (int):        number of iterations to save training log, default is 100\n",
    "    learning_rate (float):          learning rate\n",
    "    batch_size_per_gpu (int):       batchsize per gpu, default is 2 so total batchsize is 16 with 8 gpus\n",
    "    \"\"\"\n",
    "\n",
    "    # generate experiment (local) path\n",
    "    local_path = \"ch{}_T{}_betaT{}\".format(wavenet_config[\"res_channels\"],\n",
    "                                           diffusion_config[\"T\"],\n",
    "                                           diffusion_config[\"beta_T\"])\n",
    "    # Create tensorboard logger.\n",
    "    if rank == 0:\n",
    "        tb = SummaryWriter(os.path.join('exp', local_path, tensorboard_directory))\n",
    "\n",
    "    # distributed running initialization\n",
    "    if num_gpus > 1:\n",
    "        init_distributed(rank, num_gpus, group_name, **dist_config)\n",
    "\n",
    "    # Get shared output_directory ready\n",
    "    output_directory = os.path.join('exp', local_path, output_directory)\n",
    "    if rank == 0:\n",
    "        if not os.path.isdir(output_directory):\n",
    "            os.makedirs(output_directory)\n",
    "            os.chmod(output_directory, 0o775)\n",
    "        print(\"output directory\", output_directory, flush=True)\n",
    "\n",
    "    # map diffusion hyperparameters to gpu\n",
    "    for key in diffusion_hyperparams:\n",
    "        if key is not \"T\":\n",
    "            diffusion_hyperparams[key] = diffusion_hyperparams[key].cuda()\n",
    "\n",
    "    # predefine model\n",
    "    net = WaveNet(**wavenet_config).cuda()\n",
    "    print_size(net)\n",
    "\n",
    "    # apply gradient all reduce\n",
    "    if num_gpus > 1:\n",
    "        net = apply_gradient_allreduce(net)\n",
    "\n",
    "    # define optimizer\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "    # load checkpoint\n",
    "    if ckpt_iter == 'max':\n",
    "        ckpt_iter = find_max_epoch(output_directory)\n",
    "    if ckpt_iter >= 0:\n",
    "        try:\n",
    "            # load checkpoint file\n",
    "            model_path = os.path.join(output_directory, '{}.pkl'.format(ckpt_iter))\n",
    "            checkpoint = torch.load(model_path, map_location='cpu')\n",
    "\n",
    "            # feed model dict and optimizer state\n",
    "            net.load_state_dict(checkpoint['model_state_dict'])\n",
    "            if 'optimizer_state_dict' in checkpoint:\n",
    "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "            print('Successfully loaded model at iteration {}'.format(ckpt_iter))\n",
    "        except:\n",
    "            ckpt_iter = -1\n",
    "            print('No valid checkpoint model found, start training from initialization.')\n",
    "    else:\n",
    "        ckpt_iter = -1\n",
    "        print('No valid checkpoint model found, start training from initialization.')\n",
    "\n",
    "    # training\n",
    "    n_iter = ckpt_iter + 1\n",
    "    while n_iter < n_iters + 1:\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            eeg, audio = data[0].squeeze(1).cuda(), data[1].type(torch.LongTensor).cuda()\n",
    "            #print(eeg.shape,audio.shape)\n",
    "            # load audio and mel spectrogram\n",
    "            # mel_spectrogram = mel_spectrogram.cuda()\n",
    "            # audio = audio.unsqueeze(1).cuda()\n",
    "\n",
    "            # back-propagation\n",
    "            optimizer.zero_grad()\n",
    "            X = (eeg.float(), audio.float())\n",
    "            loss = training_loss(net, nn.MSELoss(), X, diffusion_hyperparams)\n",
    "            # print(loss)\n",
    "            if num_gpus > 1:\n",
    "                reduced_loss = reduce_tensor(loss.data, num_gpus).item()\n",
    "            else:\n",
    "                reduced_loss = loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # output to log\n",
    "            # note, only do this on the first gpu\n",
    "            if n_iter % iters_per_logging == 0 and rank == 0:\n",
    "                # save training loss to tensorboard\n",
    "                print(\"iteration: {} \\treduced loss: {} \\tloss: {}\".format(n_iter, reduced_loss, loss.item()))\n",
    "                tb.add_scalar(\"Log-Train-Loss\", torch.log(loss).item(), n_iter)\n",
    "                tb.add_scalar(\"Log-Train-Reduced-Loss\", np.log(reduced_loss), n_iter)\n",
    "\n",
    "            # save checkpoint\n",
    "            if n_iter > 0 and n_iter % iters_per_ckpt == 0 and rank == 0:\n",
    "                checkpoint_name = '{}.pkl'.format(n_iter)\n",
    "                torch.save({'model_state_dict': net.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict()},\n",
    "                           os.path.join(output_directory, checkpoint_name))\n",
    "                print('model at iteration %s is saved' % n_iter)\n",
    "\n",
    "            n_iter += 1\n",
    "\n",
    "    # Close TensorBoard.\n",
    "    if rank == 0:\n",
    "        tb.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46332e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Define a PyTorch dataset class\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tf_dataset, length=None):\n",
    "        self.tf_dataset = tf_dataset\n",
    "        if length:\n",
    "            self.length=length\n",
    "        else:\n",
    "            self.length = 0\n",
    "            for element in tf_dataset:\n",
    "                self.length +=1\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.tfdataset2np(self.tf_dataset.skip(idx).take(1))\n",
    "        return x[0][0], y[0][0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def tfdataset2np(self,ds):\n",
    "        x, y = map(list, zip(*list(ds.as_numpy_iterator())))\n",
    "        return x,y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c698f0dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\YLY\\miniconda3\\envs\\challenge\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "output directory exp\\ch64_T200_betaT0.02\\logs/checkpoint\n",
      "EEGWav_diff Parameters: 2.069612M\n",
      "No valid checkpoint model found, start training from initialization.\n",
      "iteration: 0 \treduced loss: 0.9940848350524902 \tloss: 0.9940848350524902\n",
      "iteration: 500 \treduced loss: 1.0314888954162598 \tloss: 1.0314888954162598\n",
      "iteration: 1000 \treduced loss: 0.9897526502609253 \tloss: 0.9897526502609253\n",
      "model at iteration 1000 is saved\n",
      "iteration: 1500 \treduced loss: 1.0127003192901611 \tloss: 1.0127003192901611\n",
      "iteration: 2000 \treduced loss: 1.0066810846328735 \tloss: 1.0066810846328735\n",
      "model at iteration 2000 is saved\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 123\u001b[0m\n\u001b[0;32m    121\u001b[0m     torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39menabled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    122\u001b[0m     torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39mbenchmark \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrain_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# Evaluate the model on test set\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# Create a dataset generator for each test subject\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m#test_files = [x for x in glob.glob(os.path.join(data_folder, \"test_-_*\")) if os.path.basename(x).split(\"_-_\")[-1].split(\".\")[0] in features]\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m#    json.dump(evaluation, fp)\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;66;03m#logging.info(f\"Results saved at {results_path}\")\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 97\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_loader, num_gpus, rank, group_name, output_directory, tensorboard_directory, ckpt_iter, n_iters, iters_per_ckpt, iters_per_logging, learning_rate, batch_size_per_gpu)\u001b[0m\n\u001b[0;32m     95\u001b[0m n_iter \u001b[38;5;241m=\u001b[39m ckpt_iter \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n_iter \u001b[38;5;241m<\u001b[39m n_iters \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 97\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader, \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m     98\u001b[0m         \u001b[38;5;66;03m# get the inputs; data is a list of [inputs, labels]\u001b[39;00m\n\u001b[0;32m     99\u001b[0m         eeg, audio \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcuda(), data[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mLongTensor)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;66;03m#print(eeg.shape,audio.shape)\u001b[39;00m\n\u001b[0;32m    101\u001b[0m         \u001b[38;5;66;03m# load audio and mel spectrogram\u001b[39;00m\n\u001b[0;32m    102\u001b[0m         \u001b[38;5;66;03m# mel_spectrogram = mel_spectrogram.cuda()\u001b[39;00m\n\u001b[0;32m    103\u001b[0m         \u001b[38;5;66;03m# audio = audio.unsqueeze(1).cuda()\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \n\u001b[0;32m    105\u001b[0m         \u001b[38;5;66;03m# back-propagation\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\challenge\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\challenge\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\challenge\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\challenge\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[2], line 17\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m---> 17\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtfdataset2np\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mskip\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m], y[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[1;32mIn[2], line 24\u001b[0m, in \u001b[0;36mCustomDataset.tfdataset2np\u001b[1;34m(self, ds)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtfdataset2np\u001b[39m(\u001b[38;5;28mself\u001b[39m,ds):\n\u001b[1;32m---> 24\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_numpy_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x,y\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\challenge\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:4770\u001b[0m, in \u001b[0;36m_NumpyIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   4767\u001b[0m     numpy\u001b[38;5;241m.\u001b[39msetflags(write\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   4768\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m numpy\n\u001b[1;32m-> 4770\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mmap_structure(to_numpy, \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\challenge\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:787\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    785\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    786\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 787\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    788\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[0;32m    789\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\challenge\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:770\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[1;32m--> 770\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    772\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    773\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    775\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    776\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\challenge\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3038\u001b[0m, in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   3036\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   3037\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3038\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3039\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIteratorGetNext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_types\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3040\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_shapes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3041\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3042\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"Example experiment for a linear baseline method.\"\"\"\n",
    "import glob\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from torch.utils.data import DataLoader\n",
    "from task2_regression.models.linear import simple_linear_model\n",
    "from task2_regression.util.dataset_generator import RegressionDataGenerator, create_tf_dataset\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_dict):\n",
    "    \"\"\"Evaluate a model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: tf.keras.Model\n",
    "        Model to evaluate.\n",
    "    test_dict: dict\n",
    "        Mapping between a subject and a tf.data.Dataset containing the test\n",
    "        set for the subject.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Mapping between a subject and the loss/evaluation score on the test set\n",
    "    \"\"\"\n",
    "    evaluation = {}\n",
    "    for subject, ds_test in test_dict.items():\n",
    "        logging.info(f\"Scores for subject {subject}:\")\n",
    "        results = model.evaluate(ds_test, verbose=2)\n",
    "        metrics = model.metrics_names\n",
    "        evaluation[subject] = dict(zip(metrics, results))\n",
    "    return evaluation\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Parameters\n",
    "    # Length of the decision window\n",
    "    window_length = 10 * 64  # 10 seconds\n",
    "    # Hop length between two consecutive decision windows\n",
    "    hop_length = 64\n",
    "    epochs = 100\n",
    "    patience = 5\n",
    "    batch_size = 1\n",
    "    only_evaluate = False\n",
    "    training_log_filename = \"training_log.csv\"\n",
    "    results_filename = 'eval.json'\n",
    "\n",
    "\n",
    "    # Get the path to the config file\n",
    "    experiments_folder = \"C:/Users/YLY/Documents/eegAudChallenge/auditory-eeg-challenge-2023-code/task2_regression\"\n",
    "    task_folder = os.path.dirname(experiments_folder)\n",
    "    config_path = os.path.join(task_folder, 'util', 'config.json')\n",
    "\n",
    "    # Load the config\n",
    "    with open(\"C:/Users/YLY/Documents/eegAudChallenge/auditory-eeg-challenge-2023-code/task2_regression/util/config.json\") as fp:\n",
    "        config = json.load(fp)\n",
    "\n",
    "    # Provide the path of the dataset\n",
    "    # which is split already to train, val, test\n",
    "\n",
    "    data_folder = os.path.join(config[\"dataset_folder\"], config[\"split_folder\"])\n",
    "    stimulus_features = [\"envelope\"]\n",
    "    features = [\"eeg\"] + stimulus_features\n",
    "\n",
    "    # Create a directory to store (intermediate) results\n",
    "    results_folder = os.path.join(experiments_folder, \"results_linear_baseline\")\n",
    "    os.makedirs(results_folder, exist_ok=True)\n",
    "\n",
    "    # create a simple linear model\n",
    "    #model = simple_linear_model()\n",
    "    #model.summary()\n",
    "    #model_path = os.path.join(results_folder, \"model.h5\")\n",
    "\n",
    "    if only_evaluate:\n",
    "    #    model = tf.keras.models.load_model(model_path)\n",
    "        print(\"evaluate\")\n",
    "    else:\n",
    "\n",
    "        train_files = [x for x in glob.glob(os.path.join(data_folder, \"train_-_*\")) if os.path.basename(x).split(\"_-_\")[-1].split(\".\")[0] in features]\n",
    "        # Create list of numpy array files\n",
    "        train_generator = RegressionDataGenerator(train_files, window_length)\n",
    "        dataset_train = create_tf_dataset(train_generator, window_length, None, hop_length, batch_size)\n",
    "\n",
    "        # Create the generator for the validation set\n",
    "        val_files = [x for x in glob.glob(os.path.join(data_folder, \"val_-_*\")) if os.path.basename(x).split(\"_-_\")[-1].split(\".\")[0] in features]\n",
    "        val_generator = RegressionDataGenerator(val_files, window_length)\n",
    "        dataset_val = create_tf_dataset(val_generator, window_length, None, hop_length, batch_size)\n",
    "        # Convert the TensorFlow dataset to a PyTorch dataset\n",
    "        train_dataset= CustomDataset(dataset_train,340585)\n",
    "        del dataset_train\n",
    "        val_dataset = CustomDataset(dataset_val,38357)\n",
    "        del dataset_val \n",
    "        #print(train_dataset.__len__(),val_dataset.__len__())\n",
    "        #print(train_dataset.__getitem__(123)[0].shape)\n",
    "        train_loader = DataLoader(\n",
    "                train_dataset, batch_size=16, shuffle=False\n",
    "            )\n",
    "        vali_loader = DataLoader(\n",
    "            val_dataset, batch_size=16, shuffle=False\n",
    "        )\n",
    "    #### train the model\n",
    "    # Parse configs. Globals nicer in this case\n",
    "        with open('train.json') as f:\n",
    "            data = f.read()\n",
    "        config = json.loads(data)\n",
    "        train_config = config[\"train_config\"]  # training parameters\n",
    "        global dist_config\n",
    "        dist_config = config[\"dist_config\"]  # to initialize distributed training\n",
    "        global wavenet_config\n",
    "        wavenet_config = config[\"wavenet_config\"]  # to define wavenet\n",
    "        global diffusion_config\n",
    "        diffusion_config = config[\"diffusion_config\"]  # basic hyperparameters\n",
    "        global trainset_config\n",
    "        trainset_config = config[\"trainset_config\"]  # to load trainset\n",
    "        global diffusion_hyperparams\n",
    "        diffusion_hyperparams = calc_diffusion_hyperparams(\n",
    "            **diffusion_config)  # dictionary of all diffusion hyperparameters\n",
    "\n",
    "        torch.backends.cudnn.enabled = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        train(train_loader, 1, 0, \"test\", **train_config)\n",
    "    \n",
    "    \n",
    "    # Evaluate the model on test set\n",
    "    # Create a dataset generator for each test subject\n",
    "    #test_files = [x for x in glob.glob(os.path.join(data_folder, \"test_-_*\")) if os.path.basename(x).split(\"_-_\")[-1].split(\".\")[0] in features]\n",
    "    # Get all different subjects from the test set\n",
    "    #subjects = list(set([os.path.basename(x).split(\"_-_\")[1] for x in test_files]))\n",
    "    #datasets_test = {}\n",
    "    # Create a generator for each subject\n",
    "    #for sub in subjects:\n",
    "    #    files_test_sub = [f for f in test_files if sub in os.path.basename(f)]\n",
    "    #    test_generator = RegressionDataGenerator(files_test_sub, window_length)\n",
    "    #    datasets_test[sub] = create_tf_dataset(test_generator, window_length, None, hop_length, 1)\n",
    "\n",
    "    # Evaluate the model\n",
    "    #evaluation = evaluate_model(model, datasets_test)\n",
    "\n",
    "    # We can save our results in a json encoded file\n",
    "    #results_path = os.path.join(results_folder, results_filename)\n",
    "    #with open(results_path, \"w\") as fp:\n",
    "    #    json.dump(evaluation, fp)\n",
    "    #logging.info(f\"Results saved at {results_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c4ee69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
