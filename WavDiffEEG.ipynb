{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfe157bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from random import randrange\n",
    "    \n",
    "###Test Streaming DataLoader with PyTorch####\n",
    "class MyIterableDataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, filePaths, frameLength, hopSize):\n",
    "            super(MyIterableDataset).__init__()\n",
    "            self.filePaths = self.group_recordings(filePaths)\n",
    "            self.frameLength = frameLength\n",
    "            self.hopSize = hopSize\n",
    "            self.filePage = len(self.filePaths)\n",
    "            self.filePool = list(range(self.filePage))\n",
    "            random.shuffle(self.filePool)\n",
    "\n",
    "            self.currentFileIndx = 0\n",
    "            self.CurrentEEG = []\n",
    "            self.CurrentAudio = []\n",
    "            self.samplePosistions = []\n",
    "\n",
    "            self.currentSampleIndex = 0\n",
    "            self.loadDataToBuffer(self.currentFileIndx)\n",
    "            \n",
    "            self.samplePosMap = []\n",
    "            self.generateSamplePostion()\n",
    "            \n",
    "    def group_recordings(self, files):\n",
    "        #Group recordings and corresponding stimuli.\n",
    "        new_files = []\n",
    "        grouped = itertools.groupby(sorted(files), lambda x: \"_-_\".join(x.stem.split(\"_-_\")[:3]))\n",
    "        for recording_name, feature_paths in grouped:\n",
    "            new_files += [sorted(feature_paths, key=lambda x: \"0\" if x == \"eeg\" else x)]\n",
    "        return new_files    \n",
    "    import random\n",
    "    \n",
    "    def loadDataToBuffer(self,fileIndex):\n",
    "        self.CurrentEEG = np.load(self.filePaths[self.filePool[self.currentFileIndx]][0]).astype(np.float32)\n",
    "        self.CurrentAudio = np.load(self.filePaths[self.filePool[self.currentFileIndx]][1]).astype(np.float32)\n",
    "\n",
    "    \n",
    "    def generateSamplePostion(self):\n",
    "        count = 0\n",
    "        for i in range(self.filePage):\n",
    "            tempAudio = np.load(self.filePaths[i][1]).astype(np.float32)\n",
    "            totalLength,_ = tempAudio.shape\n",
    "            startPos = [*range(self.frameLength, totalLength+1, self.hopSize)]\n",
    "            self.samplePosMap.append(startPos)\n",
    "            noData = (totalLength-self.frameLength)//self.hopSize + 1\n",
    "            assert len(startPos)==noData\n",
    "            count += noData\n",
    "        return count\n",
    "    def sample_random_data_number_in_one_batch(self,n, total):\n",
    "    #Return a randomly chosen list of n nonnegative integers summing to total.\n",
    "    #n: the number of total files    total: batch size\n",
    "        return [x - 1 for x in self.constrained_sum_sample_pos(n, total + n)]\n",
    "    \n",
    "    def constrained_sum_sample_pos(self,n, total):\n",
    "    #Return a randomly chosen list of n positive integers summing to total.Each such list is equally likely to occur.\"\"\"\n",
    "        dividers = sorted(random.sample(range(1, total), n - 1))\n",
    "        return [a - b for a, b in zip(dividers + [total], [0] + dividers)]\n",
    "            \n",
    "    def __iter__(self):\n",
    "       \n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.currentSampleIndex < len(self.samplePosMap[self.filePool[self.currentFileIndx]]): # still in the same file\n",
    "            thisEnd = self.samplePosMap[self.filePool[self.currentFileIndx]][self.currentSampleIndex]\n",
    "            self.currentSampleIndex += 1\n",
    "            return self.CurrentEEG[thisEnd-self.frameLength:thisEnd,:], self.CurrentAudio[thisEnd-self.frameLength:thisEnd,:]\n",
    "        else: # move to the next file\n",
    "            #print(\"next file\")\n",
    "            #### need to shuffle samples from the last file\n",
    "            random.shuffle(self.samplePosMap[self.filePool[self.currentFileIndx]])\n",
    "            self.currentFileIndx +=1\n",
    "            self.currentSampleIndex = 0\n",
    "            if self.currentFileIndx < self.filePage: # still in the same iteration\n",
    "                self.loadDataToBuffer(self.currentFileIndx)\n",
    "                thisEnd = self.samplePosMap[self.filePool[self.currentFileIndx]][self.currentSampleIndex]\n",
    "                self.currentSampleIndex += 1\n",
    "                return self.CurrentEEG[thisEnd-self.frameLength:thisEnd,:], self.CurrentAudio[thisEnd-self.frameLength:thisEnd,:]\n",
    "            else:\n",
    "                #print(\"here 2\")\n",
    "                random.shuffle(self.filePool)\n",
    "                self.currentFileIndx = 0\n",
    "                self.loadDataToBuffer(self.currentFileIndx)\n",
    "                raise StopIteration\n",
    "                print(\"iteration done, restart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1feb0a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:58: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "<>:58: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "from util import rescale, find_max_epoch, print_size\n",
    "from util import training_loss, calc_diffusion_hyperparams\n",
    "\n",
    "from distributed_util import init_distributed, apply_gradient_allreduce, reduce_tensor\n",
    "\n",
    "from models2 import EEGWav_diff as WaveNet\n",
    "\n",
    "def train(num_gpus, rank, group_name, output_directory, tensorboard_directory,\n",
    "          ckpt_iter, n_iters, iters_per_ckpt, iters_per_logging,\n",
    "          learning_rate, batch_size_per_gpu):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    num_gpus, rank, group_name:     parameters for distributed training\n",
    "    output_directory (str):         save model checkpoints to this path\n",
    "    tensorboard_directory (str):    save tensorboard events to this path\n",
    "    ckpt_iter (int or 'max'):       the pretrained checkpoint to be loaded;\n",
    "                                    automitically selects the maximum iteration if 'max' is selected\n",
    "    n_iters (int):                  number of iterations to train, default is 1M\n",
    "    iters_per_ckpt (int):           number of iterations to save checkpoint,\n",
    "                                    default is 10k, for models with residual_channel=64 this number can be larger\n",
    "    iters_per_logging (int):        number of iterations to save training log, default is 100\n",
    "    learning_rate (float):          learning rate\n",
    "    batch_size_per_gpu (int):       batchsize per gpu, default is 2 so total batchsize is 16 with 8 gpus\n",
    "    \"\"\"\n",
    "\n",
    "    # generate experiment (local) path\n",
    "    local_path = \"ch{}_T{}_betaT{}\".format(wavenet_config[\"res_channels\"],\n",
    "                                           diffusion_config[\"T\"],\n",
    "                                           diffusion_config[\"beta_T\"])\n",
    "    # Create tensorboard logger.\n",
    "    if rank == 0:\n",
    "        tb = SummaryWriter(os.path.join('exp', local_path, tensorboard_directory))\n",
    "\n",
    "    # distributed running initialization\n",
    "    if num_gpus > 1:\n",
    "        init_distributed(rank, num_gpus, group_name, **dist_config)\n",
    "\n",
    "    # Get shared output_directory ready\n",
    "    output_directory = os.path.join('exp', local_path, output_directory)\n",
    "    if rank == 0:\n",
    "        if not os.path.isdir(output_directory):\n",
    "            os.makedirs(output_directory)\n",
    "            os.chmod(output_directory, 0o775)\n",
    "        print(\"output directory\", output_directory, flush=True)\n",
    "\n",
    "    # map diffusion hyperparameters to gpu\n",
    "    for key in diffusion_hyperparams:\n",
    "        if key is not \"T\":\n",
    "            diffusion_hyperparams[key] = diffusion_hyperparams[key].cuda()\n",
    "\n",
    "    # predefine model\n",
    "    net = WaveNet(**wavenet_config).cuda()\n",
    "    print_size(net)\n",
    "\n",
    "    # apply gradient all reduce\n",
    "    if num_gpus > 1:\n",
    "        net = apply_gradient_allreduce(net)\n",
    "\n",
    "    # define optimizer\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "    # load checkpoint\n",
    "    if ckpt_iter == 'max':\n",
    "        ckpt_iter = find_max_epoch(output_directory)\n",
    "    if ckpt_iter >= 0:\n",
    "        try:\n",
    "            # load checkpoint file\n",
    "            model_path = os.path.join(output_directory, '{}.pkl'.format(ckpt_iter))\n",
    "            checkpoint = torch.load(model_path, map_location='cpu')\n",
    "\n",
    "            # feed model dict and optimizer state\n",
    "            net.load_state_dict(checkpoint['model_state_dict'])\n",
    "            if 'optimizer_state_dict' in checkpoint:\n",
    "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "            print('Successfully loaded model at iteration {}'.format(ckpt_iter))\n",
    "        except:\n",
    "            ckpt_iter = -1\n",
    "            print('No valid checkpoint model found, start training from initialization.')\n",
    "    else:\n",
    "        ckpt_iter = -1\n",
    "        print('No valid checkpoint model found, start training from initialization.')\n",
    "    \n",
    "    # Get the path to the config file\n",
    "    experiments_folder = \"C:/Users/YLY/Documents/eegAudChallenge/auditory-eeg-challenge-2023-code/task2_regression\"\n",
    "    task_folder = Path(experiments_folder)\n",
    "    config_path = task_folder/ \"util/config.json\"\n",
    "\n",
    "    with open(config_path) as fp:\n",
    "        config = json.load(fp)\n",
    "\n",
    "    data_folder = Path(config[\"dataset_folder\"])/ config[\"split_folder\"]\n",
    "    stimulus_features = [\"envelope\"]\n",
    "    features = [\"eeg\"] + stimulus_features\n",
    "\n",
    "    train_files = [path for path in Path(data_folder).resolve().glob(\"train_-_*\") if path.stem.split(\"_-_\")[-1].split(\".\")[0] in features]\n",
    "    train_dataset = MyIterableDataset(train_files,64*10,64)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=32,shuffle=False)\n",
    "        \n",
    "    # training\n",
    "    n_iter = ckpt_iter + 1\n",
    "    while n_iter < n_iters + 1:\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            eeg, audio = data[0].squeeze(1).cuda(), data[1].type(torch.LongTensor).cuda()\n",
    "            #print(eeg.shape,audio.shape)\n",
    "            # load audio and mel spectrogram\n",
    "            # mel_spectrogram = mel_spectrogram.cuda()\n",
    "            # audio = audio.unsqueeze(1).cuda()\n",
    "\n",
    "            # back-propagation\n",
    "            optimizer.zero_grad()\n",
    "            X = (eeg.float(), audio.float())\n",
    "            loss = training_loss(net, nn.MSELoss(), X, diffusion_hyperparams)\n",
    "            # print(loss)\n",
    "            if num_gpus > 1:\n",
    "                reduced_loss = reduce_tensor(loss.data, num_gpus).item()\n",
    "            else:\n",
    "                reduced_loss = loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # output to log\n",
    "            # note, only do this on the first gpu\n",
    "            if n_iter % iters_per_logging == 0 and rank == 0:\n",
    "                # save training loss to tensorboard\n",
    "                print(\"iteration: {} \\treduced loss: {} \\tloss: {}\".format(n_iter, reduced_loss, loss.item()))\n",
    "                tb.add_scalar(\"Log-Train-Loss\", torch.log(loss).item(), n_iter)\n",
    "                tb.add_scalar(\"Log-Train-Reduced-Loss\", np.log(reduced_loss), n_iter)\n",
    "\n",
    "            # save checkpoint\n",
    "            if n_iter > 0 and n_iter % iters_per_ckpt == 0 and rank == 0:\n",
    "                checkpoint_name = '{}.pkl'.format(n_iter)\n",
    "                torch.save({'model_state_dict': net.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict()},\n",
    "                           os.path.join(output_directory, checkpoint_name))\n",
    "                print('model at iteration %s is saved' % n_iter)\n",
    "\n",
    "            n_iter += 1\n",
    "\n",
    "    # Close TensorBoard.\n",
    "    if rank == 0:\n",
    "        tb.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c698f0dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output directory exp\\ch128_T200_betaT0.02\\logs/checkpoint\n",
      "EEGWav_diff Parameters: 8.254676M\n",
      "No valid checkpoint model found, start training from initialization.\n",
      "iteration: 0 \treduced loss: 1.0008398294448853 \tloss: 1.0008398294448853\n",
      "iteration: 500 \treduced loss: 0.9940957427024841 \tloss: 0.9940957427024841\n",
      "iteration: 1000 \treduced loss: 1.0008517503738403 \tloss: 1.0008517503738403\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Example experiment for a linear baseline method.\"\"\"\n",
    "import glob\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from torch.utils.data import DataLoader\n",
    "from task2_regression.models.linear import simple_linear_model\n",
    "from task2_regression.util.dataset_generator import RegressionDataGenerator, create_tf_dataset\n",
    "from pathlib import Path\n",
    "\n",
    "def evaluate_model(model, test_dict):\n",
    "    \"\"\"Evaluate a model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: tf.keras.Model\n",
    "        Model to evaluate.\n",
    "    test_dict: dict\n",
    "        Mapping between a subject and a tf.data.Dataset containing the test\n",
    "        set for the subject.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Mapping between a subject and the loss/evaluation score on the test set\n",
    "    \"\"\"\n",
    "    evaluation = {}\n",
    "    for subject, ds_test in test_dict.items():\n",
    "        logging.info(f\"Scores for subject {subject}:\")\n",
    "        results = model.evaluate(ds_test, verbose=2)\n",
    "        metrics = model.metrics_names\n",
    "        evaluation[subject] = dict(zip(metrics, results))\n",
    "    return evaluation\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Parameters\n",
    "    # Length of the decision window\n",
    "    window_length = 10 * 64  # 10 seconds\n",
    "    # Hop length between two consecutive decision windows\n",
    "    hop_length = 64\n",
    "    epochs = 100\n",
    "    patience = 5\n",
    "    batch_size = 1\n",
    "    only_evaluate = False\n",
    "    training_log_filename = \"training_log.csv\"\n",
    "    results_filename = 'eval.json'\n",
    "\n",
    "\n",
    "    # Get the path to the config file\n",
    "    experiments_folder = \"C:/Users/YLY/Documents/eegAudChallenge/auditory-eeg-challenge-2023-code/task2_regression\"\n",
    "    task_folder = os.path.dirname(experiments_folder)\n",
    "    config_path = os.path.join(task_folder, 'util', 'config.json')\n",
    "\n",
    "    # Load the config\n",
    "    with open(\"C:/Users/YLY/Documents/eegAudChallenge/auditory-eeg-challenge-2023-code/task2_regression/util/config.json\") as fp:\n",
    "        config = json.load(fp)\n",
    "\n",
    "    # Provide the path of the dataset\n",
    "    # which is split already to train, val, test\n",
    "\n",
    "    data_folder = os.path.join(config[\"dataset_folder\"], config[\"split_folder\"])\n",
    "    stimulus_features = [\"envelope\"]\n",
    "    features = [\"eeg\"] + stimulus_features\n",
    "\n",
    "    # Create a directory to store (intermediate) results\n",
    "    results_folder = os.path.join(experiments_folder, \"results_linear_baseline\")\n",
    "    os.makedirs(results_folder, exist_ok=True)\n",
    "\n",
    "    # create a simple linear model\n",
    "    #model = simple_linear_model()\n",
    "    #model.summary()\n",
    "    #model_path = os.path.join(results_folder, \"model.h5\")\n",
    "\n",
    "    if only_evaluate:\n",
    "    #    model = tf.keras.models.load_model(model_path)\n",
    "        print(\"evaluate\")\n",
    "    else:\n",
    "\n",
    "        #train_files = [x for x in glob.glob(os.path.join(data_folder, \"train_-_*\")) if os.path.basename(x).split(\"_-_\")[-1].split(\".\")[0] in features]\n",
    "        # Create list of numpy array files\n",
    "        #train_generator = RegressionDataGenerator(train_files, window_length)\n",
    "       # dataset_train = create_tf_dataset(train_generator, window_length, None, hop_length, batch_size)\n",
    "\n",
    "        # Create the generator for the validation set\n",
    "        #val_files = [x for x in glob.glob(os.path.join(data_folder, \"val_-_*\")) if os.path.basename(x).split(\"_-_\")[-1].split(\".\")[0] in features]\n",
    "        #val_generator = RegressionDataGenerator(val_files, window_length)\n",
    "        #dataset_val = create_tf_dataset(val_generator, window_length, None, hop_length, batch_size)\n",
    "        # Convert the TensorFlow dataset to a PyTorch dataset\n",
    "        #train_dataset= CustomDataset(dataset_train,340585)\n",
    "        #del dataset_train\n",
    "        #val_dataset = CustomDataset(dataset_val,38357)\n",
    "       # del dataset_val \n",
    "    #### train the model\n",
    "    # Parse configs. Globals nicer in this case\n",
    "        with open('train-2.json') as f:\n",
    "            data = f.read()\n",
    "        config = json.loads(data)\n",
    "        train_config = config[\"train_config\"]  # training parameters\n",
    "        global dist_config\n",
    "        dist_config = config[\"dist_config\"]  # to initialize distributed training\n",
    "        global wavenet_config\n",
    "        wavenet_config = config[\"wavenet_config\"]  # to define wavenet\n",
    "        global diffusion_config\n",
    "        diffusion_config = config[\"diffusion_config\"]  # basic hyperparameters\n",
    "        global trainset_config\n",
    "        trainset_config = config[\"trainset_config\"]  # to load trainset\n",
    "        global diffusion_hyperparams\n",
    "        diffusion_hyperparams = calc_diffusion_hyperparams(\n",
    "            **diffusion_config)  # dictionary of all diffusion hyperparameters\n",
    "\n",
    "        torch.backends.cudnn.enabled = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        train(1, 0, \"test\", **train_config)\n",
    "    \n",
    "    \n",
    "    # Evaluate the model on test set\n",
    "    # Create a dataset generator for each test subject\n",
    "    #test_files = [x for x in glob.glob(os.path.join(data_folder, \"test_-_*\")) if os.path.basename(x).split(\"_-_\")[-1].split(\".\")[0] in features]\n",
    "    # Get all different subjects from the test set\n",
    "    #subjects = list(set([os.path.basename(x).split(\"_-_\")[1] for x in test_files]))\n",
    "    #datasets_test = {}\n",
    "    # Create a generator for each subject\n",
    "    #for sub in subjects:\n",
    "    #    files_test_sub = [f for f in test_files if sub in os.path.basename(f)]\n",
    "    #    test_generator = RegressionDataGenerator(files_test_sub, window_length)\n",
    "    #    datasets_test[sub] = create_tf_dataset(test_generator, window_length, None, hop_length, 1)\n",
    "\n",
    "    # Evaluate the model\n",
    "    #evaluation = evaluate_model(model, datasets_test)\n",
    "\n",
    "    # We can save our results in a json encoded file\n",
    "    #results_path = os.path.join(results_folder, results_filename)\n",
    "    #with open(results_path, \"w\") as fp:\n",
    "    #    json.dump(evaluation, fp)\n",
    "    #logging.info(f\"Results saved at {results_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97daa6fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
